{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## self defined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blindness(data.Dataset):\n",
    "    def __init__(self, root_path, data_path, csv_flag, tranform=None, target_tranform=None, eval_flag=False):\n",
    "        if csv_flag is True:\n",
    "            self.dataset_information = pd.read_csv(data_path)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        self.eval_flag = eval_flag\n",
    "        self.root_path = root_path\n",
    "        self.tranform = tranform\n",
    "        self.target_tranform = target_tranform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        tmp_img_name = self.dataset_information.loc[index][\"id_code\"]\n",
    "\n",
    "        if self.eval_flag:\n",
    "            pass\n",
    "        else:\n",
    "            tmp_label = self.dataset_information.loc[index][\"diagnosis\"]\n",
    "        \n",
    "#         print(tmp_img_name)\n",
    "        img_path = self.root_path + tmp_img_name + \".png\" if self.root_path[-1] == '/' else self.root_path + '/' + tmp_img_name + \".png\"\n",
    "        img_data = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.tranform is not None:\n",
    "            img_data = self.tranform(img_data)\n",
    "            \n",
    "            if self.eval_flag:\n",
    "                return img_data, tmp_img_name\n",
    "        \n",
    "        if self.target_tranform is not None:\n",
    "            tmp_label = self.target_tranform(tmp_label)\n",
    "            \n",
    "        return img_data, tmp_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset_information.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlinessSetForTrain(data.Dataset):\n",
    "    def __init__(self, root_path, csv_path, tranform=None, target_tranform=None):\n",
    "        super(BlinessSetForTrain, self).__init__()\n",
    "        \n",
    "        self.root_path = root_path\n",
    "        self.csv_path = csv_path\n",
    "        \n",
    "        self.tranform = tranform\n",
    "        self.target_tranform = target_tranform\n",
    "        \n",
    "        self.csv_process()\n",
    "        \n",
    "    def csv_process(self):\n",
    "        self.data_collection = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        self.classes = {}\n",
    "        \n",
    "        for tmp_class in self.data_collection[\"diagnosis\"].unique():\n",
    "            self.classes[tmp_class] = self.data_collection.loc[self.data_collection[\"diagnosis\"] == tmp_class].index\n",
    "        \n",
    "        self.class_number = len(self.classes.keys())\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        tmp_key = index % self.class_number    \n",
    "        tmp_data = self.data_collection.loc[self.classes[tmp_key][index // self.class_number % 1085]]\n",
    "        \n",
    "        image_name = tmp_data[\"id_code\"]\n",
    "        image_label = tmp_data[\"diagnosis\"]\n",
    "        \n",
    "        image_path =self.root_path + image_name + \".png\" if self.root_path[-1] == '/' else self.root_path + '/' + image_name + \".png\"\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.tranform is not None:\n",
    "            image = self.tranform(image)\n",
    "        \n",
    "        if self.target_tranform is not None:\n",
    "            image_label = self.target_tranform(image_label)\n",
    "            \n",
    "        return image, image_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_collection.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform_val_list = [\n",
    "#     torchvision.transforms.Resize((256, 256), interpolation=3),\n",
    "#     torchvision.transforms.ToTensor(),\n",
    "#     torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# ]\n",
    "# data_transform = torchvision.transforms.Compose(transform_val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_root_path = \"/home/extension/kaggle/APTOS_2019_Blindness_Detection/train_images\"\n",
    "# img_csv = \"/home/hdd/hdD_Git/kaggle/image_data/classification/aptos_2019_blindness_detection/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = Blindness(img_root_path, img_csv, True, data_transform)\n",
    "# dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([64, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# for tmp in dataloader:\n",
    "#     print(tmp[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {1:1, 2:2, 3:3}\n",
    "len(a.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
